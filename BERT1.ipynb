{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "1xBG9gvJnHVlhGapkTicj5e7JyFKPUlad",
      "authorship_tag": "ABX9TyM1SCPnjH00NPz/dbgV1nHk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b3b0bfba4fd4fe983d1c8c6044f6e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d94c1084c6e04707b3aef56c81647f63",
              "IPY_MODEL_06250b0283b247008fa24f015c333343",
              "IPY_MODEL_c806a4a8369d4bb7be32cb579aa82eb6"
            ],
            "layout": "IPY_MODEL_aa357eaf9b044da1b97bb2d5c57c03f4"
          }
        },
        "d94c1084c6e04707b3aef56c81647f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae72b441edc54c0cb425b297186f1d45",
            "placeholder": "​",
            "style": "IPY_MODEL_f674c8e5e2c7433eb992a9b0c1ec5f41",
            "value": "Map: 100%"
          }
        },
        "06250b0283b247008fa24f015c333343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c6a0c4408d5482fbcb597d0771bd3a1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50b2efb1c5d0407b9d4372550970e151",
            "value": 1
          }
        },
        "c806a4a8369d4bb7be32cb579aa82eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b3d83f81e824551a2edc3a7db6efece",
            "placeholder": "​",
            "style": "IPY_MODEL_7bbbe2c8c3614d55b0f3ab51e001dcb2",
            "value": " 1/1 [00:00&lt;00:00, 43.21 examples/s]"
          }
        },
        "aa357eaf9b044da1b97bb2d5c57c03f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae72b441edc54c0cb425b297186f1d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f674c8e5e2c7433eb992a9b0c1ec5f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c6a0c4408d5482fbcb597d0771bd3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b2efb1c5d0407b9d4372550970e151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b3d83f81e824551a2edc3a7db6efece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bbbe2c8c3614d55b0f3ab51e001dcb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c5261f552e14049ba903d34a5f15502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fac2798f0a04bff9f69ccfa6d7faf7c",
              "IPY_MODEL_f7f7ce7d22cc4e5788fcfa1abe746b68",
              "IPY_MODEL_b1306d7a9ef248da86cc9ad344f1d6a5"
            ],
            "layout": "IPY_MODEL_1466302346344f3784b54385b52ced3c"
          }
        },
        "3fac2798f0a04bff9f69ccfa6d7faf7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a6d4731a0c49659a65cf49434d080a",
            "placeholder": "​",
            "style": "IPY_MODEL_be90661355d74d95a77b183984b3ba37",
            "value": "Map: 100%"
          }
        },
        "f7f7ce7d22cc4e5788fcfa1abe746b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f07f2cfae722407899c7785b65dcea8f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad815a4fc6c64643bd1442b5b9ca6aca",
            "value": 1
          }
        },
        "b1306d7a9ef248da86cc9ad344f1d6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444e03f5d47649d4a67f7a1eae9ad3eb",
            "placeholder": "​",
            "style": "IPY_MODEL_79af0714074247ab8d7483647b561459",
            "value": " 1/1 [00:00&lt;00:00, 33.45 examples/s]"
          }
        },
        "1466302346344f3784b54385b52ced3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a6d4731a0c49659a65cf49434d080a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be90661355d74d95a77b183984b3ba37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f07f2cfae722407899c7785b65dcea8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad815a4fc6c64643bd1442b5b9ca6aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "444e03f5d47649d4a67f7a1eae9ad3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79af0714074247ab8d7483647b561459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc6dba28c10340bbb1ce1e50333de690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fe606fa17664f76893570e30fc86b81",
              "IPY_MODEL_122841974a644a4283d2b3717a70cb0d",
              "IPY_MODEL_a980ead2e8e043799f035df655b2cee9"
            ],
            "layout": "IPY_MODEL_0dce9f9ae7f44c8f8fa5c319559de592"
          }
        },
        "2fe606fa17664f76893570e30fc86b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c16a3baf971418fa8f7759a0f1bbae3",
            "placeholder": "​",
            "style": "IPY_MODEL_fefdfcd0d22f4ec29ff1feb4a6df8594",
            "value": "Map: 100%"
          }
        },
        "122841974a644a4283d2b3717a70cb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4809607291e4642a6aa8ec72c7d6bc5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb62f5fede934f09b1890cc1300b521a",
            "value": 1
          }
        },
        "a980ead2e8e043799f035df655b2cee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ea687a63ed4a40bd9ed3ce5843268a",
            "placeholder": "​",
            "style": "IPY_MODEL_643ec7e2c4b24687b9a9d2c5af985bdc",
            "value": " 1/1 [00:00&lt;00:00, 37.91 examples/s]"
          }
        },
        "0dce9f9ae7f44c8f8fa5c319559de592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c16a3baf971418fa8f7759a0f1bbae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fefdfcd0d22f4ec29ff1feb4a6df8594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4809607291e4642a6aa8ec72c7d6bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb62f5fede934f09b1890cc1300b521a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96ea687a63ed4a40bd9ed3ce5843268a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643ec7e2c4b24687b9a9d2c5af985bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehoonnie/NLP1/blob/main/BERT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho4aMyEeFlgT",
        "outputId": "c24addaf-0754-4366-85c6-507d2308a3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # For uncased English\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Check if the model is loaded successfully\n",
        "print(\"BERT model and tokenizer loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eargzqy_tEh9",
        "outputId": "4678756a-3c5f-471a-b2d3-1f25122b8d56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model and tokenizer loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text\n",
        "text = \"BERT is amazing!\"\n",
        "\n",
        "# Tokenize text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"Tokenized input IDs: {inputs['input_ids']}\")\n",
        "print(f\"Attention mask: {inputs['attention_mask']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVaX63NGt3Gr",
        "outputId": "1609c98a-ffc4-494c-9e9f-b246086f6766"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input IDs: tensor([[  101, 14324,  2003,  6429,   999,   102]])\n",
            "Attention mask: tensor([[1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run input through BERT model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Outputs\n",
        "print(f\"Last hidden state shape: {outputs.last_hidden_state.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGRY3jMRt_RF",
        "outputId": "9e125031-fee6-4e9a-9560-af7cce397090"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last hidden state shape: torch.Size([1, 6, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move model and inputs to GPU\n",
        "model = model.to(device)\n",
        "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "# Run the model on GPU\n",
        "outputs = model(**inputs)\n",
        "print(f\"Output shape on GPU: {outputs.last_hidden_state.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5yQFCJsuD6X",
        "outputId": "91d08126-ce12-4943-baa2-cae5e98590f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Output shape on GPU: torch.Size([1, 6, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "# Download NLTK tokenizer if not already done\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load text from file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/911.txt\"\n",
        "with open(file_path, 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Tokenize text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Define car-related terms and hard words (examples, can be extended)\n",
        "car_related_terms = [\n",
        "    \"Porsche\", \"911\", \"hybrid\", \"turbo\", \"turbocharger\", \"GT3\", \"Carrera\",\n",
        "    \"engine\", \"flat-six\", \"GTS\", \"PDK\", \"bhp\", \"torque\"\n",
        "]\n",
        "hard_words = [\n",
        "    \"regenerative\", \"legislative\", \"embodied\", \"prototype\", \"comprehensive\",\n",
        "    \"reconfigurable\", \"intercooler\", \"aerodynamic\"\n",
        "]\n",
        "\n",
        "# Normalize tokens for comparison\n",
        "normalized_tokens = [token.lower() for token in tokens]\n",
        "\n",
        "# Label tokens\n",
        "labeled_tokens = []\n",
        "for token in tokens:\n",
        "    token_lower = token.lower()\n",
        "    if token_lower in [term.lower() for term in car_related_terms]:\n",
        "        labeled_tokens.append((token, \"Car-Related\"))\n",
        "    elif token_lower in [word.lower() for word in hard_words]:\n",
        "        labeled_tokens.append((token, \"Hard\"))\n",
        "    else:\n",
        "        labeled_tokens.append((token, \"Normal\"))\n",
        "\n",
        "# Output labeled tokens\n",
        "for token, label in labeled_tokens[:50]:  # Display the first 50 for brevity\n",
        "    print(f\"{token}: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0RL_wQjuINJ",
        "outputId": "265326e9-b87b-4403-bdba-3629b885cfba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OVERVIEW: Normal\n",
            "WHAT: Normal\n",
            "IS: Normal\n",
            "IT: Normal\n",
            "?: Normal\n",
            "It: Normal\n",
            "’: Normal\n",
            "s: Normal\n",
            "the: Normal\n",
            "same: Normal\n",
            ",: Normal\n",
            "but: Normal\n",
            "different: Normal\n",
            ".: Normal\n",
            "It: Normal\n",
            "’: Normal\n",
            "s: Normal\n",
            "the: Normal\n",
            "Porsche: Car-Related\n",
            "911: Car-Related\n",
            "as: Normal\n",
            "we: Normal\n",
            "know: Normal\n",
            "and: Normal\n",
            "love: Normal\n",
            "it: Normal\n",
            ",: Normal\n",
            "but: Normal\n",
            "it: Normal\n",
            "’: Normal\n",
            "s: Normal\n",
            "facelift: Normal\n",
            "time: Normal\n",
            "for: Normal\n",
            "the: Normal\n",
            "992: Normal\n",
            "generation: Normal\n",
            "and: Normal\n",
            "more: Normal\n",
            "has: Normal\n",
            "changed: Normal\n",
            "than: Normal\n",
            "you: Normal\n",
            "might: Normal\n",
            "think: Normal\n",
            ".: Normal\n",
            "Heck: Normal\n",
            ",: Normal\n",
            "there: Normal\n",
            "’: Normal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_-5sVKBPEtF",
        "outputId": "36be7685-1491-4fb6-9208-400ab5f9e6d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=9a2788c23bbd45c0fb07746c2471b4aa19cd315a6742344246b45201de9fc22c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from seqeval.metrics import classification_report\n",
        "import torch\n",
        "import nltk\n",
        "\n",
        "# Step 1: Load training data from `word.csv`\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/word.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "# Assuming `word.csv` has columns: `token`, `label`\n",
        "assert 'token' in train_df.columns and 'label' in train_df.columns, \"CSV must have 'token' and 'label' columns\"\n",
        "\n",
        "# Group tokens and labels by sentence if necessary\n",
        "sentences = []\n",
        "labels = []\n",
        "sentence = []\n",
        "label_list = []\n",
        "for _, row in train_df.iterrows():\n",
        "    if pd.isnull(row['token']):  # Sentence separator\n",
        "        if sentence:\n",
        "            sentences.append(sentence)\n",
        "            labels.append(label_list)\n",
        "            sentence = []\n",
        "            label_list = []\n",
        "    else:\n",
        "        sentence.append(row['token'])\n",
        "        label_list.append(row['label'])\n",
        "if sentence:  # Add the last sentence\n",
        "    sentences.append(sentence)\n",
        "    labels.append(label_list)\n",
        "\n",
        "# Map labels to IDs\n",
        "unique_labels = sorted(set(label for label_seq in labels for label in label_seq))\n",
        "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "# Convert labels to IDs\n",
        "labels = [[label2id[label] for label in label_seq] for label_seq in labels]\n",
        "\n",
        "# Create dataset\n",
        "train_data = Dataset.from_dict({\"tokens\": sentences, \"labels\": labels})\n",
        "\n",
        "# Step 2: Load evaluation text from `911.txt`\n",
        "eval_path = \"/content/drive/MyDrive/Colab Notebooks/911.txt\"\n",
        "with open(eval_path, \"r\") as f:\n",
        "    eval_text = f.read()\n",
        "\n",
        "nltk.download('punkt')\n",
        "eval_tokens = nltk.word_tokenize(eval_text)\n",
        "eval_sentences = [eval_tokens]  # Treat the whole document as one sentence\n",
        "\n",
        "# Step 3: Tokenizer and Model\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"labels\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                label_ids.append(-100)\n",
        "            else:\n",
        "                label_ids.append(label[word_id])\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_train_data = train_data.map(tokenize_and_align_labels, batched=True)\n",
        "tokenized_eval_data = Dataset.from_dict({\"tokens\": eval_sentences}).map(\n",
        "    lambda x: tokenizer(x[\"tokens\"], truncation=True, is_split_into_words=True), batched=True\n",
        ")\n",
        "\n",
        "# Load pre-trained model\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label2id))\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "# Step 4: Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Trainer setup with eval_dataset included\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_data,\n",
        "    eval_dataset=tokenized_train_data,  # Provide eval dataset here\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Step 5: Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Step 6: Evaluate on `911.txt`\n",
        "eval_output = trainer.predict(tokenized_eval_data)\n",
        "predictions = eval_output.predictions.argmax(-1)\n",
        "\n",
        "# Map predictions to labels\n",
        "predicted_labels = [[id2label[label] for label in sentence if label != -100] for sentence in predictions]\n",
        "\n",
        "# Print predictions for `911.txt`\n",
        "print(f\"Predicted labels for 911.txt: {predicted_labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "2b3b0bfba4fd4fe983d1c8c6044f6e64",
            "d94c1084c6e04707b3aef56c81647f63",
            "06250b0283b247008fa24f015c333343",
            "c806a4a8369d4bb7be32cb579aa82eb6",
            "aa357eaf9b044da1b97bb2d5c57c03f4",
            "ae72b441edc54c0cb425b297186f1d45",
            "f674c8e5e2c7433eb992a9b0c1ec5f41",
            "9c6a0c4408d5482fbcb597d0771bd3a1",
            "50b2efb1c5d0407b9d4372550970e151",
            "4b3d83f81e824551a2edc3a7db6efece",
            "7bbbe2c8c3614d55b0f3ab51e001dcb2",
            "3c5261f552e14049ba903d34a5f15502",
            "3fac2798f0a04bff9f69ccfa6d7faf7c",
            "f7f7ce7d22cc4e5788fcfa1abe746b68",
            "b1306d7a9ef248da86cc9ad344f1d6a5",
            "1466302346344f3784b54385b52ced3c",
            "87a6d4731a0c49659a65cf49434d080a",
            "be90661355d74d95a77b183984b3ba37",
            "f07f2cfae722407899c7785b65dcea8f",
            "ad815a4fc6c64643bd1442b5b9ca6aca",
            "444e03f5d47649d4a67f7a1eae9ad3eb",
            "79af0714074247ab8d7483647b561459"
          ]
        },
        "id": "E9YMrTv50JGS",
        "outputId": "aa57fdd1-1e91-4824-9624-277aacc7354d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b3b0bfba4fd4fe983d1c8c6044f6e64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c5261f552e14049ba903d34a5f15502"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-6-2bb586f98d0e>:98: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:19, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.875495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.670386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.585646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels for 911.txt: [['Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Hard', 'Hard', 'Car-Related', 'normal', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Hard', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Normal', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'normal', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Normal', 'Hard', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Hard', 'Normal', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Hard', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related', 'Car-Related']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5F8ixGtjxg0d",
        "outputId": "b4ecc632-b29f-441a-f533-9dc2f9ccc87a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow<2.19,>=2.18.0 (from tensorflow-text)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18.0->tensorflow-text)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.1.2)\n",
            "Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-text-2.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              },
              "id": "9b4c429252bf4fe481ae1f497ec665ba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the 911.txt content\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/Grancabrio.txt\"\n",
        "output_path = \"911_ground_truth.csv\"\n",
        "\n",
        "with open(input_path, \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Example: Assign ground truth labels (you can modify these)\n",
        "# Use 'Car-Related' for car terms, 'Hard' for complex terms, 'Normal' for others\n",
        "ground_truth_labels = []\n",
        "for token in tokens:\n",
        "    if token.lower() in [\"porsche\", \"911\", \"turbo\", \"hybrid\", \"gts\", \"targa\"]:\n",
        "        ground_truth_labels.append(\"Car-Related\")\n",
        "    elif token.lower() in [\"regenerative\", \"flywheel\", \"intercooler\", \"aerodynamic\"]:\n",
        "        ground_truth_labels.append(\"Hard\")\n",
        "    else:\n",
        "        ground_truth_labels.append(\"Normal\")\n",
        "\n",
        "# Create DataFrame\n",
        "ground_truth_df = pd.DataFrame({\"token\": tokens, \"label\": ground_truth_labels})\n",
        "\n",
        "# Save as CSV\n",
        "ground_truth_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Ground truth saved to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLkqEKDiRLj7",
        "outputId": "2413b4d6-7fb1-4d53-f0e0-c8ec239078c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground truth saved to 911_ground_truth.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets seqeval transformers nltk\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Download NLTK tokenizer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 1: Load and preprocess training data\n",
        "# Assuming 'word.csv' has columns: 'token', 'label'\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/word.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "assert 'token' in train_df.columns and 'label' in train_df.columns, \"CSV must have 'token' and 'label' columns\"\n",
        "\n",
        "# Group tokens and labels by sentences\n",
        "sentences = []\n",
        "labels = []\n",
        "sentence = []\n",
        "label_list = []\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "    if pd.isnull(row['token']):  # Sentence separator\n",
        "        if sentence:\n",
        "            sentences.append(sentence)\n",
        "            labels.append(label_list)\n",
        "            sentence = []\n",
        "            label_list = []\n",
        "    else:\n",
        "        sentence.append(row['token'])\n",
        "        label_list.append(row['label'])\n",
        "\n",
        "if sentence:  # Add the last sentence\n",
        "    sentences.append(sentence)\n",
        "    labels.append(label_list)\n",
        "\n",
        "# Map labels to numerical IDs\n",
        "unique_labels = sorted(set(label for label_seq in labels for label in label_seq))\n",
        "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "# Convert labels to IDs\n",
        "numerical_labels = [[label2id[label] for label in label_seq] for label_seq in labels]\n",
        "\n",
        "# Create a dataset\n",
        "train_data = Dataset.from_dict({\"tokens\": sentences, \"labels\": numerical_labels})\n",
        "\n",
        "# Step 2: Tokenization\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"labels\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                label_ids.append(-100)  # Ignore special tokens\n",
        "            else:\n",
        "                label_ids.append(label[word_id])\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_train_data = train_data.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# Step 3: Fine-tune BERT\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label2id))\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_data,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Step 4: Predict and evaluate\n",
        "# Load the Review.csv file (first 150 reviews)\n",
        "review_path = \"Review.csv\"\n",
        "review_df = pd.read_csv(review_path)\n",
        "\n",
        "# Extract the first 150 reviews\n",
        "first_150_reviews = review_df[\"Review\"].head(150).tolist()\n",
        "input_text = \"\\n\".join(first_150_reviews)\n",
        "\n",
        "# Predict function\n",
        "def predict_text(text, model, tokenizer):\n",
        "    tokens = word_tokenize(text)\n",
        "    inputs = tokenizer(tokens, return_tensors=\"pt\", is_split_into_words=True, truncation=True)\n",
        "    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "\n",
        "    # Map predictions to labels\n",
        "    predicted_labels = [id2label[label] for label in predictions if label != -100]\n",
        "    result = list(zip(tokens, predicted_labels))\n",
        "    return result\n",
        "\n",
        "# Get predictions for the first 150 reviews\n",
        "result = predict_text(input_text, model, tokenizer)\n",
        "\n",
        "# Print labeled tokens\n",
        "for token, label in result:\n",
        "    print(f\"{token}: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bc6dba28c10340bbb1ce1e50333de690",
            "2fe606fa17664f76893570e30fc86b81",
            "122841974a644a4283d2b3717a70cb0d",
            "a980ead2e8e043799f035df655b2cee9",
            "0dce9f9ae7f44c8f8fa5c319559de592",
            "1c16a3baf971418fa8f7759a0f1bbae3",
            "fefdfcd0d22f4ec29ff1feb4a6df8594",
            "d4809607291e4642a6aa8ec72c7d6bc5",
            "cb62f5fede934f09b1890cc1300b521a",
            "96ea687a63ed4a40bd9ed3ce5843268a",
            "643ec7e2c4b24687b9a9d2c5af985bdc"
          ]
        },
        "id": "O8pobSdW0uuz",
        "outputId": "ff985464-ef65-4524-fb2e-8e0552cb2041"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc6dba28c10340bbb1ce1e50333de690"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-1-ea8374f21c4b>:91: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I: Car-Related\n",
            "love: Car-Related\n",
            "this: Car-Related\n",
            "car: Car-Related\n",
            ".: Car-Related\n",
            "Gas: Car-Related\n",
            "mileage: Car-Related\n",
            ",: Car-Related\n",
            "suspension: Car-Related\n",
            ",: Car-Related\n",
            "and: Car-Related\n",
            "stereo: normal\n",
            "are: Car-Related\n",
            "great: Car-Related\n",
            ".: Car-Related\n",
            "Bluetooth: Car-Related\n",
            "integration: Car-Related\n",
            "and: Car-Related\n",
            "Pandora: Car-Related\n",
            "integration: Car-Related\n",
            "work: Car-Related\n",
            "perfectly: Car-Related\n",
            ".: Car-Related\n",
            "Suspension: Car-Related\n",
            "and: Car-Related\n",
            "noise: Car-Related\n",
            "cancellation: Car-Related\n",
            "work: Car-Related\n",
            "amazingly: Car-Related\n",
            "well: Car-Related\n",
            ".: Car-Related\n",
            "Although: Car-Related\n",
            "it: Car-Related\n",
            "looks: normal\n",
            "small: Hard\n",
            ",: Car-Related\n",
            "it: Car-Related\n",
            "has: Car-Related\n",
            "plenty: normal\n",
            "of: Car-Related\n",
            "room: Car-Related\n",
            "and: Car-Related\n",
            "has: Car-Related\n",
            "always: Car-Related\n",
            "been: Car-Related\n",
            "big: Car-Related\n",
            "enough: Car-Related\n",
            ".: Car-Related\n",
            "Gas: Car-Related\n",
            "mileage: Car-Related\n",
            "has: Car-Related\n",
            "been: Car-Related\n",
            "from: Car-Related\n",
            "42: Car-Related\n",
            "to: Car-Related\n",
            "45: Car-Related\n",
            "without: Car-Related\n",
            "really: Car-Related\n",
            "trying: Hard\n",
            ".: Car-Related\n",
            "I: Car-Related\n",
            "purchased: Car-Related\n",
            "my: Car-Related\n",
            "2013: normal\n",
            "ILX: Hard\n",
            "from: Car-Related\n",
            "the: Car-Related\n",
            "dealer: Car-Related\n",
            "used: Car-Related\n",
            "with: Car-Related\n",
            "30k: Car-Related\n",
            "miles: Hard\n",
            "in: Car-Related\n",
            "2016: Car-Related\n",
            ".: Hard\n",
            "So: Car-Related\n",
            "far: Car-Related\n",
            "so: Car-Related\n",
            "good: Car-Related\n",
            ".: Car-Related\n",
            "I: Car-Related\n",
            "had: Car-Related\n",
            "a: Hard\n",
            "Honda: Car-Related\n",
            "before: Car-Related\n",
            "and: Car-Related\n",
            "loved: Car-Related\n",
            "it: Car-Related\n",
            "so: Car-Related\n",
            "figured: Car-Related\n",
            "my: Car-Related\n",
            "next: Car-Related\n",
            "step: Car-Related\n",
            "would: Car-Related\n",
            "be: Car-Related\n",
            "an: Car-Related\n",
            "Acura: Car-Related\n",
            ".: Car-Related\n",
            "First: Car-Related\n",
            "the: Car-Related\n",
            "positives: Car-Related\n",
            ":: Car-Related\n",
            "Car: Car-Related\n",
            "rides: Car-Related\n",
            "well: Car-Related\n",
            ",: Car-Related\n",
            "love: Car-Related\n",
            "the: Hard\n",
            "GPS: Car-Related\n",
            ",: Car-Related\n",
            "blue: Car-Related\n",
            "tooth: Car-Related\n",
            "connectivity: Car-Related\n",
            ",: Car-Related\n",
            "and: Car-Related\n",
            "voice: Car-Related\n",
            "control: Car-Related\n",
            ".: Car-Related\n",
            "For: Car-Related\n",
            "a: Car-Related\n",
            "4: Car-Related\n",
            "cylinder: Car-Related\n",
            "vehicle: Car-Related\n",
            "it: Car-Related\n",
            "accelerates: Car-Related\n",
            "quite: normal\n",
            "quickly: Car-Related\n",
            "and: Car-Related\n",
            "is: Car-Related\n",
            "very: Car-Related\n",
            "good: Car-Related\n",
            "on: Car-Related\n",
            "gas: Car-Related\n",
            ".: Car-Related\n",
            "Also: Hard\n",
            "the: Car-Related\n",
            "car: Car-Related\n",
            "is: Car-Related\n",
            "spacious: Hard\n",
            ",: Car-Related\n",
            "it: Car-Related\n",
            "comfortably: Car-Related\n",
            "fit: Car-Related\n",
            "me: Car-Related\n",
            "plus: Car-Related\n",
            "3: Car-Related\n",
            "other: Hard\n",
            "adults: Car-Related\n",
            "on: Car-Related\n",
            "a: Car-Related\n",
            "short: Car-Related\n",
            "road: Car-Related\n",
            "trip: Car-Related\n",
            ".: Car-Related\n",
            "Now: Car-Related\n",
            "the: Car-Related\n",
            "not: Car-Related\n",
            "so: Car-Related\n",
            "good: Hard\n",
            ":: Car-Related\n",
            "storage: Car-Related\n",
            "is: Car-Related\n",
            "extremely: normal\n",
            "limited: Car-Related\n",
            "!: Car-Related\n",
            "the: Car-Related\n",
            "car: Car-Related\n",
            "does: Car-Related\n",
            "n't: Car-Related\n",
            "even: Car-Related\n",
            "have: Car-Related\n",
            "a: Hard\n",
            "place: Car-Related\n",
            "to: Car-Related\n",
            "put: Car-Related\n",
            "spare: Car-Related\n",
            "change: Car-Related\n",
            ",: Car-Related\n",
            "I: Car-Related\n",
            "literally: normal\n",
            "dump: Car-Related\n",
            "everything: Car-Related\n",
            "into: Car-Related\n",
            "the: Car-Related\n",
            "center: Car-Related\n",
            "counsel: Car-Related\n",
            ".: Car-Related\n",
            "Also: Car-Related\n",
            "the: Hard\n",
            "USB: Car-Related\n",
            "cord: Car-Related\n",
            "is: Car-Related\n",
            "awkwardly: Car-Related\n",
            "placed: Car-Related\n",
            ",: Car-Related\n",
            "when: Car-Related\n",
            "I: Car-Related\n",
            "first: Car-Related\n",
            "test: Hard\n",
            "drove: Car-Related\n",
            "the: Car-Related\n",
            "car: Car-Related\n",
            "I: Car-Related\n",
            "thought: Car-Related\n",
            "it: Car-Related\n",
            "was: Hard\n",
            "damaged: Hard\n",
            "(: Car-Related\n",
            "if: Car-Related\n",
            "you: Car-Related\n",
            "'ve: Car-Related\n",
            "seen: Car-Related\n",
            "it: Car-Related\n",
            "you: Car-Related\n",
            "know: Car-Related\n",
            "what: Car-Related\n",
            "I: Car-Related\n",
            "mean: Car-Related\n",
            "): Car-Related\n",
            ".: Car-Related\n",
            "Lastly: Car-Related\n",
            ",: normal\n",
            "I: Car-Related\n",
            "got: Car-Related\n",
            "the: Car-Related\n",
            "tech: Car-Related\n",
            "package: Car-Related\n",
            "so: Car-Related\n",
            "I: Car-Related\n",
            "have: Car-Related\n",
            "leather: Car-Related\n",
            "seats: normal\n",
            "but: Car-Related\n",
            "when: normal\n",
            "I: Car-Related\n",
            "first: Car-Related\n",
            "started: Car-Related\n",
            "looking: Car-Related\n",
            "I: Car-Related\n",
            "was: Car-Related\n",
            "shocked: Car-Related\n",
            "to: Car-Related\n",
            "see: Car-Related\n",
            "that: Car-Related\n",
            "the: Car-Related\n",
            "base: Car-Related\n",
            "model: Car-Related\n",
            "comes: Car-Related\n",
            "standard: Car-Related\n",
            "with: Car-Related\n",
            "cloth: Car-Related\n",
            "seats: Car-Related\n",
            ",: Car-Related\n",
            "I: Car-Related\n",
            "'ve: Car-Related\n",
            "never: Car-Related\n",
            "seen: Car-Related\n",
            "a: Car-Related\n",
            "luxury: Car-Related\n",
            "car: Car-Related\n",
            "with: Car-Related\n",
            "cloth: Car-Related\n",
            "seats: Car-Related\n",
            ".: Car-Related\n",
            "I: Car-Related\n",
            "recently: Car-Related\n",
            "purchased: Car-Related\n",
            "a: Car-Related\n",
            "2013: Car-Related\n",
            "ILX: Car-Related\n",
            "with: Car-Related\n",
            "the: Car-Related\n",
            "Tech: Car-Related\n",
            "pkg: Car-Related\n",
            ",: Car-Related\n",
            "and: Car-Related\n",
            "I: normal\n",
            "am: Hard\n",
            "very: Car-Related\n",
            "pleased: Car-Related\n",
            "with: Car-Related\n",
            "it: Car-Related\n",
            ".: Car-Related\n",
            "I: Car-Related\n",
            "had: Car-Related\n",
            "a: Car-Related\n",
            "2008: Car-Related\n",
            "Acura: Car-Related\n",
            "TL: Car-Related\n",
            "prior: Car-Related\n",
            "to: Car-Related\n",
            "purchasing: Car-Related\n",
            "this: Car-Related\n",
            "car: Car-Related\n",
            ",: Car-Related\n",
            "and: Hard\n",
            "I: Car-Related\n",
            "thought: Car-Related\n",
            "I: normal\n",
            "would: Car-Related\n",
            "miss: Car-Related\n",
            "the: Car-Related\n",
            "V6: Car-Related\n",
            "acceleration: Car-Related\n",
            ",: Car-Related\n",
            "but: Car-Related\n",
            "I: Car-Related\n",
            "honestly: Car-Related\n",
            "do: Car-Related\n",
            "n't: Car-Related\n",
            ".: Car-Related\n",
            "A: Car-Related\n",
            "lot: normal\n",
            "of: Car-Related\n",
            "the: Car-Related\n",
            "reviews: Hard\n",
            "say: Car-Related\n",
            "the: Car-Related\n",
            "150: Car-Related\n",
            "hp: Car-Related\n",
            "is: Car-Related\n",
            "underpowered: Car-Related\n",
            ",: normal\n",
            "but: Hard\n",
            "I: Car-Related\n",
            "find: Car-Related\n",
            "the: Car-Related\n",
            "car: Car-Related\n",
            "to: Car-Related\n",
            "be: Car-Related\n",
            "adequate: normal\n",
            ".: Car-Related\n",
            "In: Car-Related\n",
            "fact: Car-Related\n",
            ",: Car-Related\n",
            "it: Car-Related\n",
            "picks: Car-Related\n",
            "up: Car-Related\n",
            "quite: Car-Related\n",
            "nicely: Car-Related\n",
            "on: Car-Related\n",
            "the: Car-Related\n",
            "highway: Car-Related\n",
            "and: normal\n",
            "I: Car-Related\n",
            "do: Car-Related\n",
            "n't: Car-Related\n",
            "have: Car-Related\n",
            "trouble: Car-Related\n",
            "passing: Car-Related\n",
            "cars: Car-Related\n",
            ".: Car-Related\n",
            "The: normal\n",
            "interior: Car-Related\n",
            "is: Car-Related\n",
            "nice: normal\n",
            ",: Car-Related\n",
            "well: Car-Related\n",
            "built: Hard\n",
            ",: Hard\n",
            "and: Car-Related\n",
            "feels: Car-Related\n",
            "a: Car-Related\n",
            "lot: Car-Related\n",
            "wider: Car-Related\n",
            "than: Car-Related\n",
            "what: Car-Related\n",
            "the: Car-Related\n",
            "outside: Car-Related\n",
            "appearance: Car-Related\n",
            "would: Car-Related\n",
            "make: Car-Related\n",
            "you: Car-Related\n",
            "believe: Car-Related\n",
            ".: normal\n",
            "The: Car-Related\n",
            "rear: Car-Related\n",
            "leg: Car-Related\n",
            "room: Car-Related\n",
            "is: Car-Related\n",
            "also: Car-Related\n",
            "excellent: Car-Related\n",
            "considering: normal\n",
            "this: Car-Related\n",
            "is: Car-Related\n",
            "a: Car-Related\n",
            "compact: Hard\n",
            "car: Car-Related\n",
            ".: Car-Related\n",
            "As: Car-Related\n",
            "stated: Car-Related\n",
            "above: Car-Related\n",
            ",: Car-Related\n",
            "this: Car-Related\n",
            "is: Car-Related\n",
            "an: Car-Related\n",
            "excellent: Car-Related\n",
            "commuter: Car-Related\n",
            "car: Car-Related\n",
            ".: Car-Related\n",
            "We: Car-Related\n",
            "bought: Car-Related\n",
            "our: Car-Related\n",
            "ILX: Car-Related\n",
            "used: Car-Related\n",
            "and: Car-Related\n",
            "have: Car-Related\n",
            "been: Car-Related\n",
            "incredibly: Car-Related\n",
            "pleased: Car-Related\n",
            "with: Car-Related\n",
            "it: normal\n",
            "thus: Hard\n",
            "far: Hard\n",
            ".: Hard\n",
            "As: normal\n",
            "a: Car-Related\n",
            "former: Car-Related\n",
            "Prius: Hard\n",
            "owner: Car-Related\n",
            ",: Car-Related\n",
            "I: Car-Related\n",
            "feel: Hard\n",
            "much: Hard\n",
            "cooler: Car-Related\n",
            "driving: Car-Related\n",
            "this: Car-Related\n",
            "sporty: Car-Related\n",
            "Acura: Car-Related\n",
            ",: Car-Related\n",
            "although: Car-Related\n",
            "I: Car-Related\n",
            "do: Car-Related\n",
            "miss: Car-Related\n",
            "the: Car-Related\n",
            "50+: Car-Related\n",
            "mpg: Hard\n",
            "of: Car-Related\n",
            "the: normal\n",
            "Prius: normal\n",
            ".: Car-Related\n",
            "It: Car-Related\n",
            "'s: Car-Related\n",
            "fun: Car-Related\n",
            "to: Car-Related\n",
            "drive: normal\n",
            ",: Car-Related\n",
            "handles: Car-Related\n",
            "well: Hard\n",
            ",: Car-Related\n",
            "stops: Car-Related\n",
            "on: Car-Related\n",
            "a: Car-Related\n",
            "dime: Car-Related\n",
            ",: Car-Related\n",
            "and: Car-Related\n",
            "has: Car-Related\n",
            "all: Car-Related\n",
            "of: Car-Related\n",
            "the: Car-Related\n",
            "modern: Car-Related\n",
            "features: Car-Related\n",
            "you: Car-Related\n",
            "'d: Car-Related\n",
            "expect: Car-Related\n",
            "from: Car-Related\n",
            "an: Car-Related\n",
            "Acura: Car-Related\n",
            ".: Car-Related\n",
            "I: Car-Related\n",
            "primarily: Car-Related\n",
            "drive: Car-Related\n",
            "around: normal\n",
            "town: Car-Related\n",
            "(: Car-Related\n",
            "about: Car-Related\n",
            "90: Car-Related\n",
            "%: Car-Related\n",
            "of: Car-Related\n",
            "the: Hard\n",
            "time: Car-Related\n",
            "): Car-Related\n",
            "with: Car-Related\n",
            "lots: Car-Related\n",
            "of: Car-Related\n",
            "stopping: normal\n",
            "and: Car-Related\n",
            "am: Car-Related\n",
            "averaging: Car-Related\n",
            "about: Car-Related\n",
            "37-38: Car-Related\n",
            "mpg: Car-Related\n",
            ".: Car-Related\n",
            "I: Car-Related\n",
            "love: Car-Related\n",
            "the: Car-Related\n",
            "simplicity: Car-Related\n",
            "of: Car-Related\n",
            "the: Car-Related\n",
            "interior: Car-Related\n",
            ",: Car-Related\n",
            "which: normal\n",
            "is: Car-Related\n",
            "easy: Car-Related\n",
            "to: Car-Related\n",
            "use: Car-Related\n",
            "and: Car-Related\n",
            "not: Car-Related\n",
            "as: Car-Related\n",
            "bright: Car-Related\n",
            "or: Car-Related\n",
            "busy: Car-Related\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model and tokenizer\n",
        "output_dir = \"./saved_model\"\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(output_dir)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkdczj4k4CH3",
        "outputId": "7a25ceb0-038d-493f-c84c-3f073d441269"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to ./saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_checkpoint = \"./saved_model\"  # Path to your fine-tuned model directory\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Load text from the uploaded file\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/911.txt\"\n",
        "output_path = \"911_highlighted.txt\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Function to predict labels for tokens\n",
        "def predict_tokens(tokens, model, tokenizer):\n",
        "    inputs = tokenizer(tokens, return_tensors=\"pt\", is_split_into_words=True, truncation=True)\n",
        "    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Predict labels\n",
        "model.eval()\n",
        "predictions = predict_tokens(tokens, model, tokenizer)\n",
        "\n",
        "# Map predictions back to labels\n",
        "id2label = {0: \"Normal\", 1: \"Car-Related\", 2: \"Hard\"}  # Replace with your label mapping\n",
        "labeled_tokens = [(token, id2label[pred]) for token, pred in zip(tokens, predictions)]\n",
        "\n",
        "# Generate highlighted text for a TXT file\n",
        "highlighted_text = \"\"\n",
        "for token, label in labeled_tokens:\n",
        "    if label == \"Car-Related\":\n",
        "        highlighted_text += f\"<<blue>>{token}<<end>> \"\n",
        "    elif label == \"Hard\":\n",
        "        highlighted_text += f\"<<yellow>>{token}<<end>> \"\n",
        "    else:\n",
        "        highlighted_text += f\"{token} \"\n",
        "\n",
        "# Save the highlighted text to a TXT file\n",
        "with open(output_path, \"w\") as output_file:\n",
        "    output_file.write(highlighted_text.strip())\n",
        "\n",
        "print(f\"Highlighted text saved to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L95z2kxj1ozw",
        "outputId": "88d582f7-01cb-46c5-f22c-cfdcc7f57e32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highlighted text saved to 911_highlighted.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ksWYGKQObM",
        "outputId": "0b2c4671-dae7-4449-ee0d-828aa70296a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# car-related 단어 추출\n",
        "car_related_words = [token for token, label in labeled_tokens if label == \"Car-Related\"]"
      ],
      "metadata": {
        "id": "VoMHsdDp_rvq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "for word in car_related_words[:10]:  # 10개 단어만 처리\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if synsets:\n",
        "        definition = synsets[0].definition()  # 첫 번째 synset의 정의 사용\n",
        "        print(f\"{word}: {definition}\")\n",
        "    else:\n",
        "        print(f\"{word}: WordNet에서 정의를 찾을 수 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo3dm5TqAQHt",
        "outputId": "65146766-6421-46a8-ec63-51f7ad962ca8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "992: WordNet에서 정의를 찾을 수 없습니다.\n",
            "now: the momentary present\n",
            "A: a metric unit of length equal to one ten billionth of a meter (or 0.0001 micron); used to specify wavelengths of electromagnetic radiation\n",
            "hybrid: a word that is composed of parts from different languages (e.g., `monolingual' has a Greek prefix and a Latin root)\n",
            "if: WordNet에서 정의를 찾을 수 없습니다.\n",
            "developed: make something new, such as a product or a mental or artistic creation\n",
            "turbocharged: WordNet에서 정의를 찾을 수 없습니다.\n",
            "flat-six: WordNet에서 정의를 찾을 수 없습니다.\n",
            "of: WordNet에서 정의를 찾을 수 없습니다.\n",
            "and: WordNet에서 정의를 찾을 수 없습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6tHdhmKAmfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}